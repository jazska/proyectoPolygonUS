# Proyecto de Clase: Detecci√≥n de Noticias Falsas con BERT y KNIME

## Descripci√≥n

Este proyecto busca resolver el problema de la **identificaci√≥n autom√°tica de noticias falsas** en espa√±ol, combinando enfoques cl√°sicos de machine learning con modelos modernos de lenguaje (LLM). Se parte de un dataset real con textos noticiosos y se aplica un flujo de an√°lisis que incluye preprocesamiento, vectorizaci√≥n, entrenamiento y evaluaci√≥n de modelos.

---

## Objetivo

Desarrollar un sistema capaz de clasificar noticias como **verdaderas** o **falsas**, utilizando:

- Algoritmos tradicionales como **Naive Bayes** en KNIME
- Modelos de lenguaje como **BERT** en Google Colab con GPU

---

## Metodolog√≠a

### 1. Gesti√≥n del proyecto

- Plan metodol√≥gico dise√±ado en **Notion** al igual que el s eguimiento de tareas

### 2. Obtenci√≥n del dataset

- Dataset consolidado en CSV con columnas: `titulo`, `texto`, `clase`
- Fuentes: Kaggle, Internet y datos propios

### 3. Documentaci√≥n t√©cnica

- Repositorio en GitHub con:
  - Scripts de entrenamiento en Python
  - Flujos de trabajo en KNIME
  - Visualizaciones y m√©tricas
  - Archivos `.md` explicativos

### 4. An√°lisis en KNIME

- Conversi√≥n a documentos
- Limpieza de texto (puntuaci√≥n, stemming)
- Vectorizaci√≥n con Bag of Words
- Entrenamiento con Naive Bayes
- Evaluaci√≥n con `Scorer`
**Flujo de procesamiento en KNIME**
Este flujo incluye lectura del dataset, preprocesamiento de texto, vectorizaci√≥n y entrenamiento con Naive Bayes.

![Flujo en KNIME](assets/1.png)

**Resultados:**
- Accuracy: `42.7‚ÄØ%`
- Error: `57.3‚ÄØ%`
- Cohen‚Äôs Kappa: `0.0`

### 5. Entrenamiento con BERT en Colab

- Modelo: `bert-base-multilingual-cased`
- Tokenizaci√≥n, entrenamiento y evaluaci√≥n con `transformers` y `datasets`
- GPU activada para acelerar el proceso

**Resultados:**
- Accuracy: `97.2‚ÄØ%`
- F1 Score: `0.972`
- Precision y Recall: `0.972`
- Tiempo de entrenamiento: `36 segundos`

### 6. Automatizaci√≥n con LLM

- Generaci√≥n de c√≥digo Python
- Documentaci√≥n del flujo
- Creaci√≥n de scripts de visualizaci√≥n
- Redacci√≥n de publicaciones para LinkedIn

---

## Herramientas utilizadas

| Categor√≠a              | Herramienta                        |
|------------------------|------------------------------------|
| Gesti√≥n de proyectos   | Notion                             |
| An√°lisis de datos      | KNIME, Python, pandas              |
| Modelos de lenguaje    | Hugging Face Transformers, BERT    |
| Automatizaci√≥n         | LLM (Copilot, ChatGPT)             |    
| Repositorio t√©cnico    | GitHub                             |

---

## Contenido del repositorio

- [x] Flujo en KNIME 
- [x] Script de entrenamiento en Colab con BERT
- [x] m√©tricas
- [x] Repositorio en GitHub con todos los recursos


---

## Comparativa de modelos

## üìä Interpretaci√≥n m√©trica por m√©trica

| M√©trica              | Naive Bayes (KNIME) | BERT (Colab) | Interpretaci√≥n |
|----------------------|---------------------|--------------|----------------|
| **Accuracy**         | 42.7‚ÄØ%              | 97.2‚ÄØ%       | BERT logra clasificar correctamente casi todas las muestras, mientras que Naive Bayes falla en m√°s de la mitad. |
| **Error**            | 57.3‚ÄØ%              | 11.2‚ÄØ%       | El modelo cl√°sico comete errores en m√°s de la mitad de los casos; BERT tiene un margen de error muy bajo. |
| **F1 Score**         | ‚Äî                   | 0.972        | BERT tiene un excelente equilibrio entre precisi√≥n y exhaustividad. Naive Bayes no reporta esta m√©trica, pero se estima baja. |
| **Cohen‚Äôs Kappa**    | 0.0                 | ‚Äî            | El modelo de KNIME no tiene mejor desempe√±o que una clasificaci√≥n aleatoria. BERT no reporta esta m√©trica, pero ser√≠a alta. |

---

## Conclusiones

- Los modelos cl√°sicos como Naive Bayes son √∫tiles como baseline, pero tienen limitaciones sem√°nticas
- BERT ofrece una mejora significativa en precisi√≥n y velocidad cuando se entrena en GPU
- La combinaci√≥n de herramientas como KNIME, Python y LLM permite un flujo de trabajo robusto, automatizado y colaborativo
- Documentar y publicar el proyecto en GitHub y LinkedIn fortalece la visibilidad profesional y el aprendizaje t√©cnico

---

## Repositorio del modelo
A continuaci√≥n se muestra una captura de los archivos generados y subidos al repositorio de Hugging Face:

![Archivos del modelo en Hugging Face](assets/2.png)

Link de acceso al modelo:
[Hugging Face: jazska/fake-news-detector-es](https://huggingface.co/jazska/fake-news-detector-es)

---

## Cr√©ditos

Proyecto desarrollado como parte del curso de an√°lisis de datos y automatizaci√≥n con LLM.  
Incluye integraci√≥n de herramientas de gesti√≥n, visualizaci√≥n, entrenamiento y publicaci√≥n t√©cnica.
