# Proyecto de Clase: Detecci√≥n de Noticias Falsas con BERT y KNIME

## Descripci√≥n

Este proyecto busca resolver el problema de la **identificaci√≥n autom√°tica de noticias falsas** en espa√±ol, combinando enfoques cl√°sicos de machine learning con modelos modernos de lenguaje (LLM). Se parte de un dataset real con textos noticiosos y se aplica un flujo de an√°lisis que incluye preprocesamiento, vectorizaci√≥n, entrenamiento y evaluaci√≥n de modelos.

---

## Objetivo

Desarrollar un sistema capaz de clasificar noticias como **verdaderas** o **falsas**, utilizando:

- Algoritmos tradicionales como **Naive Bayes** en KNIME
- Modelos de lenguaje como **BERT** en Google Colab con GPU

---

## Metodolog√≠a

### 1. Gesti√≥n del proyecto

- Plan metodol√≥gico dise√±ado en **Notion** al igual que el s eguimiento de tareas

### 2. Obtenci√≥n del dataset

- Dataset consolidado en CSV con columnas: `titulo`, `texto`, `clase`
- Fuentes: Kaggle, Internet y datos propios

### 3. Documentaci√≥n t√©cnica

- Repositorio en GitHub con:
  - Scripts de entrenamiento en Python
  - Flujos de trabajo en KNIME
  - Visualizaciones y m√©tricas
  - Archivos `.md` explicativos

### 4. An√°lisis en KNIME

- Conversi√≥n a documentos
- Limpieza de texto (puntuaci√≥n, stemming)
- Vectorizaci√≥n con Bag of Words
- Entrenamiento con Naive Bayes
- Evaluaci√≥n con `Scorer`

**Resultados:**
- Accuracy: `42.7‚ÄØ%`
- Error: `57.3‚ÄØ%`
- Cohen‚Äôs Kappa: `0.0`

### 5. Entrenamiento con BERT en Colab

- Modelo: `bert-base-multilingual-cased`
- Tokenizaci√≥n, entrenamiento y evaluaci√≥n con `transformers` y `datasets`
- GPU activada para acelerar el proceso

**Resultados:**
- Accuracy: `97.2‚ÄØ%`
- F1 Score: `0.972`
- Precision y Recall: `0.972`
- Tiempo de entrenamiento: `36 segundos`

### 6. Automatizaci√≥n con LLM

- Generaci√≥n de c√≥digo Python
- Documentaci√≥n del flujo
- Creaci√≥n de scripts de visualizaci√≥n
- Redacci√≥n de publicaciones para LinkedIn

---

## Herramientas utilizadas

| Categor√≠a              | Herramienta                        |
|------------------------|------------------------------------|
| Gesti√≥n de proyectos   | Notion, Trello, ClickUP            |
| An√°lisis de datos      | KNIME, Python, pandas              |
| Modelos de lenguaje    | Hugging Face Transformers, BERT    |
| Automatizaci√≥n         | LLM (Copilot, ChatGPT, etc.)       |
| Visualizaci√≥n          | Matplotlib, plot_tree, KNIME views |
| Repositorio t√©cnico    | GitHub                             |

---

## Entregables

- [x] Flujo en KNIME documentado
- [x] Script de entrenamiento en Colab con BERT
- [x] Visualizaciones de m√©tricas
- [x] Publicaci√≥n en LinkedIn
- [x] Repositorio en GitHub con todos los recursos
- [x] Pitch en video explicando la propuesta

---

## Comparativa de modelos

| M√©trica              | Naive Bayes (KNIME) | BERT (Colab) |
|----------------------|---------------------|--------------|
| Accuracy             | 42.7‚ÄØ%              | 97.2‚ÄØ%       |
| Error                | 57.3‚ÄØ%              | 11.2‚ÄØ%       |
| F1 Score             | ‚Äî                   | 0.972        |
| Cohen‚Äôs Kappa        | 0.0                 | ‚Äî            |

---

## Conclusiones

- Los modelos cl√°sicos como Naive Bayes son √∫tiles como baseline, pero tienen limitaciones sem√°nticas
- BERT ofrece una mejora significativa en precisi√≥n y velocidad cuando se entrena en GPU
- La combinaci√≥n de herramientas como KNIME, Python y LLM permite un flujo de trabajo robusto, automatizado y colaborativo
- Documentar y publicar el proyecto en GitHub y LinkedIn fortalece la visibilidad profesional y el aprendizaje t√©cnico

---

## Repositorio del modelo

üìÅ [Hugging Face: jazska/fake-news-detector-es](https://huggingface.co/jazska/fake-news-detector-es)

---

## Cr√©ditos

Proyecto desarrollado como parte del curso de an√°lisis de datos y automatizaci√≥n con LLM.  
Incluye integraci√≥n de herramientas de gesti√≥n, visualizaci√≥n, entrenamiento y publicaci√≥n t√©cnica.
